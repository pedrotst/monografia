%\chapter{Aprendizado de Redes Bayesianas}
\label{ch:aprendizado}
Muitas vezes, quando queremos construir uma \gls{bn}, o conhecimento do relacionamento de causa entre as variáveis do nosso dominio pode ser incerto, o custo de um especialista muito elevado, e principalmente, precisar as probabilidades dos de cada nó dados seus pode ser inviável. No entanto, se tivermos dados sobre o problema, isto pode facilitar muito esse processo de criação da \gls{bn}, tudo que precisamos fazer é adaptar técnicas de aprendizado de máquina para o escopo de \glspl{bn}. Pensando nisto o interesse em desenvolver e implementar estas técnicas vem aumentando nos últimos anos.

É importante observar que as probabilidades representadas por \gls{bn} pode ser Bayesiana ou Física. Quando construímos uma \gls{bn} a partir de conhecimento prévio tão somente, as probabilidades serão Bayesianas. No entanto se aprendermos estas estruturas a partir de dados, estas probabilidades serão físicas \cite{heck95}.

O aprendizado de uma \gls{bn} é dividido em duas etapas distintas e independentes
\begin{itemize}
	\item O Aprendizado da Estrutura da rede. Isto é, quais as relações de causas entre as variáveis do nosso domínio.
	\item O Aprendizado dos Parâmetros da rede. Isto é, dada a estrutura da rede, quais as probabilidades de cada um dos nós.
\end{itemize}

Obviamente para se aprender os parâmetros de uma rede é necessário que já se tenha a estrutura da pronta. Esta estrutura pode ter sido construída por um especialista, ou aprendida pelos dados. Entretanto o aprendizado de parâmetro é trivial de ser feito e por este motivo já se tornou uma tradição entre as publicações sobre de Aprendizado de Redes Bayesianas apresentar a aprendizagem de parâmetros antes da aprendizagem de estrutura. Nós também seguiremos esta tradição.

\section{Aprendizado de Parâmetros}
O aprendizado de parâmetros nada mais que encontrar a distribuição de probabilidade conjunta de cada variável aleatória presente na reade, representadas por \glspl{cpt}, dada a topologia da rede.

Seja $\textbf{X} = {X_1,X_2,...,X_n}$ para o conjunto de variáveis aleatórias do model, $B(S)$ para a estrutura da \gls{bn} e $\theta_s$ para os parâmetros da \gls{bn}. Pearl \cite{pearl88} provou que a função de distribuição conjunta de $\textbf{X}$ pode ser obitida como o produto das distribuições de probabilidades condicionais da variável da \gls{bn}, dado os seus pais. A partir da \autoref{eq:pearl} temos que:
\begin{equation}
	P(\textbf{X}|\theta_s, B(S)) = \prod_{i=1}^{n}p(x_i|pa_i,\theta_i,B(S))
\end{equation}
Onde $\theta_i$ é o vetor de prâmetros para $P(x_i|pa_i, \theta_i, B(S))$, $\theta_s$ é o vetor de parâmetros de $(\theta_1,...,\theta_n)$. O que desejamos é econtrar os parâmetros $\theta_s$ dado um conjunto de treinamento $D$ e a estrutura $B(S)$. Para isto avaliamos a expressão $P(\theta_s| D,B(S))$. É importante notar que $D$ deve ser um conjunto de terinamento completo e é respresentado por ${x_1,x_2,...,x_n}$, onde cada $x_i$ representa um caso do conjunto de dados observados. As incertezas são codificadas sobre os parâmetros $\theta_s$ por uma variável aleatória $\Theta_s$ e a função a priori $P(\theta_s|B(S))$. A função $P(x_i|pa_i,\theta_i,B(S))$ é vista como a função de distribuição local.

\iffalse
	Assumindo que se trata de dados discretos a função de distribuição local será dada por:
	\begin{equation}
	p(x_{i}^{k}|pa_{i}^{j},\theta_i, B(S)) = \theta_{ijk} > 0
	\end{equation}
	onde $pa_{i}^1,...,pa_{i}^{q_i}$são as $q_i$ instâncias possíveis dos pais de $x_i$, $\theta_i=((\theta_{ijk})_{k=1}^{r_i})_{j=1}^{q_i}$ e $\theta_{ijk}$ é a probabilidade de ocorrência do k-ésimo valor de $x_i$, dada a j-ésima configuração de pais de $x_i$, o vetor de parâmetros $\theta_i$ dessa distribuição de probabilidades e a estrutura $B(S)$.
\fi

A partir de manipulações aritméticas que fogem do escopo deste trabalho chegamos na seguinte equação:
\begin{equation}
P(X_i=x_i^k|Pais = pa_i^j) = \frac{\alpha_{ijk}+N_{ijk}}{\sum_{i}^{r_i}\alpha_{ijk}+N_{ij}}
\label{eq:param_learn}
\end{equation}

Seja o domínio de $X_i$ denotado por $D_{x_i}$
\begin{itemize}
	\item $X_i$ é a i-ésima variável da rede bayesiana;
	\item $x_i^k \in D_{x_i}$ é a k-ésima instância da variável $X_i$;
	\item $pa_i^j$ é a j-ésima instância da variável $X_i$;
	\item $\alpha_{ijk}$ é o parâmetro da distribuição de Dirichlet;
	\item $r_i$ é a cardinalidade dos estados da variável $X_i$, de $D_{x_i}$;
	\item $N_{ij}$ é o número total de ocorrências de $X_i$ dados os seus pais; $pa_i^j$, isto é, $N_{ij}=\sum_{k=1}^{n}N_{ijk}$
\end{itemize}

Os parâmetros $\alpha_{ijk}$ podem ser substituídos por 1, pois corresponde ao valor esperado da frequência de cada estado, admitindo-se uma distribuição uniforme para os estados de $X_i$, visto que, a princípio, não se tem nenhuma informação que permita estimação melhor para essa distribuição de probabilidades.

A seguir daremos um exemplo da aplicação dessa fórmula para o aprendizado da rede Ásia \ref{fig:red_asia} proposto por Lauritzen e Spielgelhater \cite{lauritzen88}. A tabela com os dados foi retirada de \cite{custodio05}


\begin{figure}[ht]
	\centering
	\includegraphics{figuras/red_asia}
	\caption[Rede Ásia]{Rede Ásia}
	\label{fig:red_asia}
\end{figure}

\begin{figure}[ht]
	\centering
	\includegraphics{figuras/tabela_asia}
	\caption[Dados para Treinamento para a rede Ásia]{Exemplo de conjunto de treinamento para a Rede Ásia}
	\label{fig:tabela_asia}
\end{figure}

\newtheorem{exmp}{Exemplo}[chapter]
\begin{exmp}
	Neste exemplo desejamos aprender os parâmetros para a variável dispnéia da rede Àsia, a partir do conjunto de treinamento apresentado na Tabela \ref{fig:tabela_asia}
\end{exmp}


Os pais da variável da variável Dispneia são TouC (coluna 4) e Bronquite (coluna 6), portanto $pa_7=[4,6]$. Os estados de TouC e Bronquite são, respectivamente representados por:
\begin{itemize}
	\item $D_x[4]=[0,1]$, onde 0 representa 'Não' e 1 'Sim'; 
	\item $D_x[6]=[0,1]$, onde 0 representa 'Ausente' e 1 representa 'Presente'.
\end{itemize} 
As possíveis instâncias para Dispneia são: $pa_7 = [[0,0]^0, [0,1]^1,[1,0]^2,[1,1]^3]$ onde por exemplo a instância 2: $[1,0]^2$ representa TouC assumindo o valor 'Sim ' e Bronquite assumindo o valor 'Ausente'.

A matriz $N_{ijk}$ para dispnéia, obtida através da contagem na matriz D das ocorrências de Dispneia, condicionadas as instâncias possíveis para os pais TouC e Bronquite, está apresentada na \refTab{tab:disp}

\tabela{Matriz $N_{ijk}$ Para Dispneia com Pais T ou C e Bronquite}{tab:disp}{| c | c | c | c | c |}%
{\hline
	& \multicolumn{4}{|c|}{Instancia dos Pais} \\\hline
	Dispneia & 0 & 1 & 2 & 3 \\\hline
	0 & 3 & 2 & 1 & 0 \\\hline
	1 & 1 & 7 & 0 & 0 \\\hline
	}%
A partir dessa taela é possível calcular a probabilidade associada a cada parâmetro da distribuição de probabilidade da variável aleatória DIspneia. A tabela de probabiliades condicionais de Dispneia, calculada com a \ref{eq:param_learn}, está representada na \refTab{tab:cpt_disp}

\tabela{CPT calculada para Dispneia}{tab:cpt_disp}{| c | c | c | c | c | c |}%
{\hline
	& TouC & 0 & 0 & 0 & 1 \\\hline
	& Bronquite & 0 & 1 & 0 & 1\\\hline\rule[-2.5ex]{0pt}{7ex}
	\multirow{2}{*}{Dispneia} & Sim & $\frac{1+3}{2+4} = 0.67$ & $\frac{1+2}{2+9} = 0.27$ & $\frac{1+1}{2+1} = 0.67$ & $\frac{1+0}{2+0} = 0.5$ \\\cline{2-6}\rule[-2.5ex]{0pt}{7ex}
	& Não & $\frac{1+1}{2+4}=0.33$ & $\frac{1+7}{2+9}=0.73$ & $\frac{1+0}{2+1}=0.33$ & $\frac{1+0}{2+0}=0.5$\\\hline
	
	
	
}%

\section{Aprendizado de Estrutura}
O Objetivo da aprendizagem da Estrutura é encontrar a topologia da \gls{bn} que mais se adéqua aos nossos dados. Para isto podemos atacar o problema de duas formas distintas:

\begin{itemize}
	\item Busca e pontuação: fazemos uma busca no conjunto de todos \gls{dag} existentes entre nossas variáveis usando heurísticas robustas o suficiente.
	\item Análise de dependência: utilizamos técnicas estatísticas bem desenvolvidas para analisar a dependência entre nossos dados e a partir deles inferir a estrutura da rede.
\end{itemize}


Vamos começar discutindo sobre algoritmos de busca e pontuação, apresentamos as heurísticas mais famosas e descrevemos o algoritmo K2 e o B. Em seguida apresentaremos os algoritmos baseados em dependencia condicional, os quais dependem fortemente do conceito de d-separação, uma vez que é a d-separação que nos permite fazer asserções acerca da dependência das variáveis na rede.

\subsection{Busca e Pontuação}
A ideia dos algoritmos de Busca e Pontuação consiste em procurar pela rede que melhor se adere aos nossos dados dentro do universo de todas redes possíveis, isto é, que maximize a probabilidade posterior de acordo com os dados.No entanto este problema foi demonstrado ser NP-Completo \cite{chickering96}, podendo se tornar NP-Hard caso o tamanho do banco de dados seja grande o suficiente \cite{chickering04}. Seja como for, boas técnicas heurísticas são necessárias para maximizar esta busca.

As funções de pontuação mais famosas são:
\begin{itemize}
	\item Cooper \& Herkovits \cite{cooper92} derivaram a seguinte função a partir de algumas suposições básicas, listadas mais a seguir:
	\begin{equation}
	CH(X_i, pa_i) = \prod_{j=1}^{q_i}\frac{(r_i - 1)!}{(r_i + N_{ij} - 1)!}.\prod_{k=1}^{r_i}N_{ijk}
	\end{equation}

	\item \gls{mdl}\cite{cheng02} é bedeado na idéia que o melhor modelo é uma coleção de dados que minimiza a soma do comprimento de dados que codifica o modelo.
	\begin{equation}
	MDL(X_i,pa_i) = (\prod_{j=1}^{q_i}\prod_{k=1}^{r_i}N_{ijk}log\frac{N_{ijk}}{N_{ij}})-\frac{1}{2}q_i(r_i-1)logN
	\end{equation}

	\item Similarmente ao \gls{mdl}, a heurística \gls{mml} busca minimizar minimizar o comprimento da mensagem codificada.
	\begin{equation}
	MML(X_i,pa_i) = log_2 n + \frac{n(n-1)}{2}-log_2Bits
	\end{equation}
	onde BITS é a quantidade de bits necessária para codificar a ordenação total das variáveis.
\end{itemize}

\subsubsection{O Algoritmo K2}
\begin{figure}[htb]
	\centering
	\includegraphics[width = 450px]{figuras/K2}
	\caption{Pseudocódigo do algoritmo K2 (retirado de \cite{cooper92})}
	\label{fig:K2}
\end{figure}
Juntamente da métrica CH Cooper \& Herkovits \cite{cooper92} definiram um algoritmo muito simples de aprendizado que denominaram K2, pois era visto como uma melhoria de um algoritmo já existente, o Katató.

A ideia principal do algoritmo K2 é inserir nós de forma gulosa\footnote{Busca gulosa: do inglês greedy search} entre as variáveis até que nenhum nó seja capaz de aumentar a probabilidade da rede. Para isto é necessário informar uma ordem total entre os nós.

Primeiramente assume-se quatro fatores para se aplicar o algoritmo:

\begin{enumerate}
	\item As variáveis do banco de dados são discretos. Caso os dados hajam valores contínuos é necessário discretizá-los. 
	
	\item Os casos ocorrem de forma independente. Por exemplo, se uma moeda é justa (50\% de chance de cair cara), então o fato do primeiro lançamento dar cara não influencia nossa crença do segundo lançamento também dar cara.
	
	\item Não há casos com valores faltantes.
	
	\item As estruturas são igualmente prováveis.
	
\end{enumerate}
Na \autoref{fig:K2} apresentamos o pseudocódigo do algoritmo K2, onde $\pi_i \equiv pa_i$, isto é, os pais de $x_i$  e $g(i, \pi_i)$ é alguma métrica de pontuação.

\subsubsection{O Algoritmo B}
\begin{figure}[htb]
	\centering
	\includegraphics[width = 300px]{figuras/B_Algorithm}
	\caption{Pseudocódigo do algoritmo B (retirado de \cite{buntine91})}
	\label{fig:B_algorithm}
\end{figure}
O algoritmo B proposto em 1991 por Buntine \cite{buntine91} nada mais é que uma generalização do K2 utilizando beam search. A ideia de Buntine era propor um algoritmo e extendê-lo para ser capaz de aplicar incremental learning, isto é, poder adicionar dados e continuar o aprendizado da rede mesmo depois de ela pronta, sem necessitar fazer recomputações desnecessárias.

Beam search é uma especialização do Breadth-first search, com parâmetros de quantos sucessores devemos expadir. Portanto o algoritmo B recebe quatro parâmetros 1 > C > D > E. Se a posterior da estrutura for menor que E marcamos aquela estrutura como morta, isto é, não se explora mais seus descendentes. C e D são os parâmetros do Beam Search. Quando C, D e E se aproximam de 1 o algoritmo se reduz ao K2.

Além disto também devemos informar uma ordenação total das variáveis, assim como no algoritmo K2.

A \autoref{fig:B_algorithm} mostra um pseudocódigo do algoritmo B.

Outros algoritmos que podemos citar são as árvores de chowliu\cite{chow68}, kutató\cite{kutato13}, K2, Wong-Xiang\cite{wong94}, Lam-Bacchus\cite{lam94}, Benedict\cite{benedict96}, Suzuki\cite{suzuki96}, Friedman-Goldszmidt\cite{friedman97}.
\subsection{Análise de Dependência}
Para a classe de algoritmos de Análise de Dependência é assumido que a estrutura da rede representa perfeitamente as dependências e independências do domínio. A validade de uma independência pode ser verificada realizando-se um teste estatístico usando o banco de dado sobre o domínio. A idéia geral desta classe de algoritmos é a seguinte:

\begin{enumerate}
	\item Iniciar com um grafo não direcionado sobre V;
	\item Remover o Arco entre dois nós u e v para o qual um conjunto de variáveis $S \subseteq V\backslash \{uv\} $ pode ser encontrado tal que u e v são condicionalmente independentes dados S;
	\item Selecionar arcos e nós e associar uma direção aos arcos para formar um v-nó na estrutura
	\item Associar direções aos arcos restantes tal que um grafo direcionado acíclico seja formado.
\end{enumerate}
A diferença básica entre os vários algoritmos neste enfoque está no modo como os conjuntos de variáveis S são encontrados e nas regras de associação da direcionalidade.

Podemos citar como exemplos os algoritmos CBL \cite{cbl98} e indução causal, proposto por Pearl \cite{pearl91}



